Here are comprehensive, high-density study notes covering the provided material. These notes are structured to be self-contained, bridging the gap between theoretical concepts (textbook/slides) and practical application (exam style), with a heavy focus on architecture and code logic.

-----

# **Subject: Operating Systems - I/O, Concurrency, and Architecture**

**Source Material Integrated:** OSTEP Ch. 36, Lecture Slides (17-io), 2024 Final Exam.

-----

## **Part 1: I/O System Architecture**

### **1.1 The Hierarchical Structure**

Modern computer systems utilize a hierarchical bus structure based on **physics** (faster signals require shorter distances) and **cost**.

  * **Memory Bus (Proprietary/Interconnect):** Highest speed. Connects CPU to Memory (DRAM). Short, expensive, custom-designed.
  * **General I/O Bus (e.g., PCI, PCIe):** High speed. Connects high-performance devices (Graphics, NICs).
  * **Peripheral Bus (e.g., SCSI, SATA, USB):** Lower speed, longer physical distance. Connects "slow" devices (Disks, Mice, Keyboards).

**Modern Architecture (Intel Z270 Example):**

  * **Northbridge (Integrated into CPU):** Memory controller and Graphics lanes (PCIe) are now often on the CPU die for speed.
  * **DMI (Direct Media Interface):** Connects the CPU to the I/O Chip (Southbridge).
  * **Southbridge (I/O Chip):** Manages slower connections (SATA, USB, Legacy Audio/LAN).

### **1.2 The Canonical Device**

Any I/O device can be abstracted into two parts:

1.  **Interface (Visible to OS):**
      * **Status Register:** Read to check condition (`BUSY`, `READY`, `ERROR`).
      * **Command Register:** Write to trigger execution.
      * **Data Register:** Read/Write to pass data.
2.  **Internals (Hidden):**
      * Micro-controller (CPU), private memory (SRAM/DRAM), and specific hardware (e.g., disk arm motors).
      * *Note:* Complex devices (RAID controllers) are essentially small computers running their own **firmware**.

-----

## **Part 2: I/O Protocols & Data Movement**

### **2.1 The Canonical Protocol (PIO)**

This is the basic interaction loop using **Programmed I/O (PIO)**.

**Algorithm:**

1.  **Polling:** Loop reading `Status` until `BUSY` is cleared.
2.  **Data Transfer:** CPU writes data to `Data` register.
3.  **Command:** CPU writes to `Command` register (starts device).
4.  **Completion:** CPU loops reading `Status` until `BUSY` clears again (check for success/error).

**Critique:**

  * **Pro:** Simple, working logic.
  * **Con:** **Inefficient.** The CPU wastes cycles **spinning** (polling) while waiting for slow devices.

### **2.2 Interrupts**

Instead of polling, the OS puts the calling process to sleep and context switches. When the device finishes, it raises a **Hardware Interrupt**.

  * **Workflow:** CPU issues command $\rightarrow$ Context Switch $\rightarrow$ CPU runs Process B $\rightarrow$ Device finishes $\rightarrow$ Interrupt fires $\rightarrow$ OS runs **ISR** (Interrupt Service Routine) $\rightarrow$ Wake Process A.
  * **Trade-off:** Interrupts are not always better.
      * **Slow Device:** Interrupts are best (overlap computation with I/O).
      * **Fast Device:** Polling is best. The overhead of context switching and ISR handling $>$ the time spent spinning.
      * **Hybrid Strategy:** Poll for a short time; if not done, sleep (use interrupts).

**Livelock Condition (Network Receive):**
If a storm of interrupts arrives (e.g., packet flood), the CPU may spend 100% of its time processing ISRs and never execute user-level code.

  * *Solution:* **Coalescing** (device waits to bundle multiple events into one interrupt) or temporarily switching to polling during high load.

### **2.3 Direct Memory Access (DMA)**

Solves the "Data Movement" overhead of PIO.

  * **Problem with PIO:** CPU must manually copy data `Memory` $\leftrightarrow$ `Device` one word at a time.
  * **Solution (DMA):** A specific hardware engine on the bus.
      * OS tells DMA: *Source Address, Dest Address, Size.*
      * DMA handles the copy.
      * DMA raises an interrupt when the copy is complete.
  * **Benefit:** CPU is free to compute while data is moving.

-----

## **Part 3: Device Interaction Mechanics**

### **3.1 Addressing Devices**

How does the CPU instructions target a specific device register?

1.  **Explicit I/O Instructions (Port-Mapped):**
      * x86 instructions: `in` and `out`.
      * Address space is distinct from main memory (I/O Ports).
      * *Privileged* instructions (OS only).
      * *Example:* `outb(0x3f6, 0)` writes to port 0x3f6.
2.  **Memory-Mapped I/O:**
      * Device registers are mapped to physical memory addresses.
      * OS uses standard `load` / `store` instructions.
      * Hardware routes these addresses to the device, not RAM.
      * *Advantage:* No new instructions needed; compiler optimization possible (careful with `volatile`).

### **3.2 Device Drivers**

**The Crux:** How to fit specific devices into a generic OS?

  * **Abstraction:** The OS (File System) talks to a **Generic Block Layer**, which talks to the **Device Driver**.
  * **Encapsulation:** All device-specific code (registers, timing, interrupts) is hidden inside the driver.
  * **Reliability Issue:** Drivers account for \>70% of OS code and are the primary cause of kernel crashes (often written by third parties, not kernel experts).

-----

## **Part 4: Code Case Study: xv6 IDE Disk Driver**

*Relevant for code analysis questions.*

**Key Constants:**

  * `0x1F7`: Command/Status Register.
  * `0x1F2`: Sector Count.
  * `0x1F3 - 0x1F6`: LBA (Logical Block Address) registers.
  * `IDE_BSY` (Busy), `IDE_DRDY` (Drive Ready), `IDE_DF` (Drive Fault).

**1. Wait Ready (Polling Function):**

```c
static int ide_wait_ready() {
    // Read status port (0x1f7)
    // Loop while BUSY is set OR READY is NOT set
    while (((int r = inb(0x1f7)) & IDE_BSY) || !(r & IDE_DRDY))
        ; // spin
    return 0; // simplified
}
```

**2. Start Request (Issuing I/O):**

```c
static void ide_start_request(struct buf *b) {
    ide_wait_ready();       // Ensure drive is idle
    outb(0x3f6, 0);         // Enable interrupts (Control Reg)
    outb(0x1f2, 1);         // Sector count = 1
    // ... write LBA to 0x1f3-0x1f6 ...
    
    if (b->flags & B_DIRTY) {
        outb(0x1f7, CMD_WRITE);     // Send Write Command
        outsl(0x1f0, b->data, 512/4); // Transfer data (PIO)
    } else {
        outb(0x1f7, CMD_READ);      // Send Read Command
    }
}
```

**3. Interrupt Handler:**

```c
void ide_intr() {
    // ... acquire lock ...
    // If it was a Read, now we grab the data
    if (!(b->flags & B_DIRTY) && ide_wait_ready() >= 0)
        insl(0x1f0, b->data, 512/4);
    
    b->flags |= B_VALID; // Mark buffer valid
    wakeup(b);           // Wake the sleeping process
    // Start next request in queue...
}
```

-----

## **Part 5: Concurrency & Exam Specifics**

*(Derived from Final Exam content which focuses on application of architecture logic)*

### **5.1 Thread State Sharing**

When multiple threads run in a single process (POSIX):

  * **Shared:** Heap memory, Global variables, Open file descriptors, Signal handlers, Parent PID.
  * **Private (Unique per thread):** Stack (local variables), Registers (SP, PC), Thread ID, Stack Pointer.

### **5.2 Cost of Operations (Lowest to Highest)**

1.  **Procedure Call:** Just saving return address/registers.
2.  **Branch/Jump:** Pipeline flush risks.
3.  **User-level Thread Switch:** Save/restore registers (no kernel entry).
4.  **Kernel-level Thread Switch:** Trap to kernel, full context switch, scheduler involvement.

### **5.3 Synchronization Algorithms**

#### **A. The Bakery Algorithm (Software Mutual Exclusion)**

Used when hardware atomic instructions are unavailable.

  * **Ticket Logic:** Threads take a "number" (ticket). The holder of the lowest number enters the Critical Section (CS).
  * **Handling Ties:** If tickets are equal, the thread with the lower PID wins.
  * **Crucial Variables:**
      * `choosing[i]`: Bool. True while thread $i$ is picking a number. Prevents race conditions during ticket assignment.
      * `number[i]`: Int. The ticket value. 0 means "not interested."
  * **Starvation:** **Impossible.** The algorithm is First-Come-First-Served (FCFS) based on ticket numbers.
  * **Failure Mode:** If `choosing` is removed, a race condition occurs where two threads calculate the same `max` and enter CS simultaneously because the tie-breaker check might be read before the write completes.

#### **B. Barriers (Synchronization)**

Wait until $N$ threads reach a point.

**Implementation with Semaphores (2 Threads):**
Use two semaphores to ensure lock-step arrival.

```c
// Two threads: T0, T1
sema_t s[2]; // Init both to 0

void barrier2(int me) { // me is 0 or 1
    int peer = 1 - me;
    sema_signal(&s[me]); // Tell peer "I arrived"
    sema_wait(&s[peer]); // Wait for peer to arrive
}
```

**Implementation with Mutex & CondVar (N Threads):**

```c
mutex_t m;
cond_t cv;
int count = 0;
int N = 5;

void barrier(int me) {
    mutex_lock(&m);
    count++;
    if (count == N) {
        cond_broadcast(&cv); // All arrived, wake everyone
        // count = 0; // Reset for reusable barrier
    } else {
        cond_wait(&cv, &m); // Sleep and release lock
    }
    mutex_unlock(&m);
}
```

-----

## **Part 6: Storage & File Systems**

### **6.1 Hardware Mechanics**

  * **HDD:**
      * **Spindle:** Motor spinning the platters.
      * **Track Buffer:** Built-in RAM cache on the disk (8-64MB) to smooth speed differences.
      * **Seek:** Moving the arm. **Rotation:** Waiting for sector. **Transfer:** Reading bits.
  * **SSD:**
      * **Read Disturbance:** Reading a specific page frequently can cause bit-flips in *neighboring* pages within the same block due to voltage leaks.
  * **fsync():** System call that forces dirty data from OS memory to the physical disk (reliability).

### **6.2 File System Structures (FAT vs. Inode)**

  * **FAT (File Allocation Table):**
      * Linked-list map stored at the start of the volume.
      * Entry per block. Value = Next block index.
      * **Bad for Random Access:** Must traverse the link chain.
  * **Full Path Indexing (Optimization):**
      * Instead of recursive directory lookup (`/` -\> `usr` -\> `bin` -\> `ls`), maintain a global hash map: `"/usr/bin/ls" -> Inode 10`.
      * **Time:** Lookup is $O(1)$ (hashing) vs $O(d)$ (depth of tree).
      * **Space:** Huge requirement. Storing full strings for every file consumes massive RAM/Disk space compared to hierarchical dentries.
      * **Symlinks:** Hard to implement. A symbolic link is a path alias; full path indexing maps strict Paths to Inodes. You'd need a secondary map or flag logic.

-----

## **Part 7: Exam Checklist (Quick Reference)**

| Concept | Explanation |
| :--- | :--- |
| **Race Condition** | Multiple threads update shared data; outcome depends on timing. |
| **Spin Lock** | Lock that loops (spins). Requires **preemptive** scheduler on single CPU. |
| **Livelock** | System doing work (ISRs) but making no progress (User tasks). |
| **Memory-Mapped I/O** | `load/store` to device addresses. No `in/out` instructions. |
| **DMA** | Offloads `copy` task from CPU. Interrupts CPU when done. |
| **Stack Memory** | **Private** to thread. Contains local vars, return address. |
| **Heap Memory** | **Shared** by all threads in a process. |
| **Bakery Algo** | Software mutex. Uses "choosing" to simulate atomicity. |
| **Barrier** | Sync point. $T_1 \dots T_N$ must all arrive before any proceed. |