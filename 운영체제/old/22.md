Based on the style of the attached final exam (which emphasizes precise algorithmic steps, understanding of concurrency/atomicity, and system architecture) and the content of the provided lecture slides and textbook chapter, here is a comprehensive study note.

This note is designed to be **self-contained**, allowing you to grasp the internal logic without referring back to the text, while focusing on the technical details likely to appear in a "code" or "protocol" analysis question.

---

# **Topic: File System Crash Consistency & Journaling**

## **I. The Crash Consistency Problem**

The fundamental problem is that the file system (FS) needs to update multiple on-disk structures atomically to complete a single logical operation (e.g., appending a file), but the disk only guarantees atomicity for a single sector write.

### **1. The Anatomy of an Update**
Consider appending a data block ($D_b$) to an existing file. This requires three separate physical writes:
1.  **Inode ($I$):** Update file size and add the pointer to the new block.
2.  **Data Bitmap ($B$):** Mark the new block as allocated.
3.  **Data Block ($D_b$):** Write the actual user data to the disk.

### **2. Crash Scenarios**
If the OS crashes or power fails, only a subset of these writes may complete.
* **Case 1: Only $D_b$ written.**
    * *Result:* Data is on disk, but no inode points to it, and bitmap says it's free.
    * *Status:* **Safe.** The data is effectively lost, but the FS structure is consistent.
* **Case 2: Only Inode ($I$) written.**
    * *Result:* Inode points to an address containing garbage (since $D_b$ wasn't written).
    * *Status:* **Inconsistent & Dangerous.** Reading the file returns garbage.
* **Case 3: Only Bitmap ($B$) written.**
    * *Result:* Bitmap says block is used, but no inode points to it.
    * *Status:* **Space Leak.** The block will never be used or freed.
* **Case 4: Inode ($I$) + Bitmap ($B$) written (No $D_b$).**
    * *Result:* Metadata is consistent, but the file points to garbage data.
    * *Status:* **Privacy/Data integrity risk.**

---

## **II. Solution 1: The File System Checker (FSCK)**

The "Lazy" approach: let the crash happen, then scan the *entire* disk on reboot to find and fix inconsistencies.

### **FSCK Phases & Logic**
1.  **Superblock Check:** Sanity checks (e.g., FS size vs. block count).
2.  **Free Blocks:**
    * Scan all inodes/indirect blocks to see which blocks are actually in use.
    * *Rule:* Trust the **Inodes** over the **Bitmaps**. If the bitmap says "free" but an inode uses it, fix the bitmap.
3.  **Inode State:** Check for corruption (e.g., invalid type fields). Clear suspect inodes.
4.  **Inode Links:**
    * Traverse the entire directory tree to calculate actual link counts.
    * *Fix:* Update the inode's link count to match the traversal. If an allocated inode has 0 links but is not in the free map, move it to `lost+found`.
5.  **Duplicates:** Check if two inodes point to the same block.
    * *Fix:* Clear one, or copy the block so each has a private copy.
6.  **Bad Blocks:** Check for pointers outside valid partition range.

### **Critique**
* **Pros:** Conceptually simple.
* **Cons:** **Too Slow.** Runtime is proportional to the size of the *disk* ($O(N)$), not the size of the changes. On large RAIDs, this can take hours.

---

## **III. Solution 2: Journaling (Write-Ahead Logging)**

The "Active" approach: borrowed from databases. Write a description of what you *plan* to do (the note) before overwriting the actual structures.

### **1. Basic Concepts**
* **The Journal:** A reserved area on disk (or a separate device) treated as a circular log.
* **Transaction:** A set of updates grouped together.
* **Checkpointing:** The process of writing the committed transaction data to its final on-disk location.
* **Idempotency:** The property that replaying a transaction multiple times has the same effect as playing it once (crucial for recovery).

### **2. Protocol A: Data Journaling (Full Journaling)**
This mode logs *everything* (Metadata + User Data). It offers the highest safety but is the slowest.

#### **The Protocol Steps:**
1.  **Journal Write:** Write `TxB` (Transaction Begin), `Inode`, `Bitmap`, and `Data` to the log.
2.  **Journal Commit:** Write `TxE` (Transaction End) to the log.
    * *Atomicity:* This is usually a single 512-byte sector write. If this completes, the transaction is valid.
3.  **Checkpoint:** Write `Inode`, `Bitmap`, and `Data` to their actual locations in the main FS.
4.  **Free:** Mark the transaction as free in the journal superblock (allowing reuse).

#### **Recovery Logic:**
* Scan log.
* If `TxB` and `TxE` exist $\rightarrow$ **Replay** (Write blocks to main FS).
* If `TxB` exists but no `TxE` $\rightarrow$ Crash happened during log write. **Discard** (Do nothing).

#### **Performance Analysis:**
* **Double Write Penalty:** Every data block is written to disk twice (once to log, once to FS). This halves write bandwidth.

---

### **3. Protocol B: Metadata Journaling (Ordered Journaling)**
This is the default in Linux ext3/ext4. It logs only metadata, but carefully orders writes to ensure data consistency.

#### **The "Pointer vs. Pointed-to" Rule:**
Never point to an object (data) until the object has been initialized (written to disk).

#### **The Protocol Steps (Critical for Exam):**
1.  **Data Write:** Write **User Data** ($D_b$) to its final location in the main FS.
    * *Wait:* Must complete before step 3.
2.  **Journal Write:** Write `TxB` and **Metadata** ($I$, $B$) to the log.
3.  **Journal Commit:** Write `TxE` to the log.
    * *Constraint:* Steps 1 and 2 must finish before issuing Step 3.
4.  **Checkpoint:** Write **Metadata** ($I$, $B$) to their final locations in the main FS.
5.  **Free:** Mark log space as free.

#### **Recovery Logic:**
* If crash happens after Step 3: Replay metadata. The inode will point to $D_b$, which is guaranteed to be correct because of Step 1.
* If crash happens before Step 3: Discard metadata. The inode doesn't update, so the file doesn't point to the new data. The data written in Step 1 is effectively "invisible" (just lost).

---

## **IV. Advanced Scenarios & Optimizations**

### **1. The Block Reuse Problem (Tricky Case)**
This occurs in Metadata Journaling because data blocks are not journaled.

* **Scenario:**
    1.  User deletes directory `foo` (frees Block 1000).
    2.  FS commits this delete to Journal.
    3.  User creates file `bar`. FS selects freed Block 1000 for `bar`'s data.
    4.  FS writes `bar`'s data to Block 1000.
    5.  **CRASH** happens before `bar`'s inode is committed.
* **The Hazard:**
    * On reboot, FS replays the Journal (Step 2).
    * The Journal says "Directory `foo` used Block 1000."
    * Replay overwrites Block 1000 with `foo`'s old directory data.
    * **Result:** `bar`'s data (written in Step 4) is corrupted by the replay.
* **Solution: Revoke Records.**
    * When a block is freed, write a **Revoke Record** to the journal.
    * During recovery, if the FS sees a Revoke Record for Block 1000, it **skips** any replay actions that would modify Block 1000.

### **2. Optimizations**
* **Batching:** Instead of committing every single system call (create, write, unlink) individually, buffer them into a global transaction (e.g., every 5 seconds).
* **Circular Log:** Treat the journal as a ring buffer. Use a "Journal Superblock" to track the `head` and `tail` of valid transactions.
* **Checksumming (Transactional Checksums):**
    * *Problem:* Normally, you must write `TxB` + `Content`, wait, then write `TxE` (to ensure `TxE` isn't written if content fails). This wait is slow.
    * *Solution:* Include a checksum of the transaction body inside `TxB` and `TxE`.
    * *Benefit:* You can write `TxB`, `Content`, and `TxE` all at once. During recovery, calculate the checksum. If it doesn't match, the transaction is invalid (ignore it).

---

## **V. Summary of Complexity vs. Consistency**

| Method | Consistency Guarantee | Data Writes | Performance | Recovery Speed |
| :--- | :--- | :--- | :--- | :--- |
| **FSCK** | Metadata only | 1x | High (normal op) / Very Low (boot) | Very Slow ($O(Disk)$) |
| **Data Journaling** | Meta + Data | 2x | Low (Double Write) | Fast ($O(Log)$) |
| **Ordered Journaling** | Meta + Data (no garbage pointers) | 1x | High | Fast ($O(Log)$) |
| **Soft Updates** | Meta + Data | 1x | High (Complex implementation) | N/A (No log) |

## **VI. Implementation Note: Barriers**
To implement the ordering requirements (e.g., "Write Data BEFORE Commit"), the OS uses **Write Barriers**.
* A write barrier ensures that all write requests issued *before* the barrier reach the physical media before any write requests issued *after* the barrier.
* Disks with write caches may violate this unless explicitly flushed.

---

### **Quick Exam Checklist**
1.  **If asked to design a barrier:** Remember that Data Journaling allows `TxB`, `Meta`, `Data` to be issued in parallel, but `TxE` must wait. Ordered Journaling requires `Data` to complete before `TxE` is issued.
2.  **If asked about "Garbage Data":** This implies the Inode was updated to point to a block, but the block write didn't finish. Ordered journaling fixes this by forcing the data write first.
3.  **If asked about recovery time:** Journaling is $O(Log Size)$. FSCK is $O(Disk Size)$.