Based on the materials provided (HDD slides, Textbook chapter on Disks, and the Spring 2024 Final Exam), here is a comprehensive **High-Yield Study Guide**.

This guide is structured to cover the **theoretical foundations** (from the slides/textbook) and the **practical application/code patterns** (from the exam). It is designed to be self-containedâ€”you should not need to open the textbook to understand the logic.

-----

# ðŸ“š Operating Systems Final Review: Storage & Concurrency

## Part 1: Hard Disk Drives (HDD)

*Focus: Physical mechanics, performance math, and scheduling algorithms.*

### 1.1 Physical Geometry

To understand HDD performance, you must understand the moving parts.

  * **Platter:** The circular disk coated with magnetic material. Data is stored on both sides (surfaces).
  * **Spindle:** The motor that spins the platters at a constant speed (measured in **RPM**, e.g., 7,200 or 15,000 RPM).
  * **Track:** Concentric circles on a platter.
  * **Cylinder:** The set of all tracks with the same diameter across all platters.
  * **Sector:** The smallest unit of addressable storage (traditionally 512 bytes, modern 4KB).
  * **Head/Arm:** The mechanism that reads/writes data. All heads move together (attached to the same arm assembly).

### 1.2 I/O Performance (The "Crux")

The time to access data is the sum of three delays. This is the **most important formula** for disk performance.

$$T_{I/O} = T_{seek} + T_{rotation} + T_{transfer}$$

1.  **Seek Time ($T_{seek}$):** Time to move the arm to the correct track.
      * *Mechanical:* Slowest part (ms range).
      * *Note:* Average seek time is roughly $1/3$ of full seek time.
2.  **Rotational Delay ($T_{rotation}$):** Time for the desired sector to rotate under the head.
      * Depends on RPM.
      * **Average Rotational Delay:** $\frac{1}{2} \times \frac{60,000 \text{ ms}}{\text{RPM}}$
      * *Example:* 7200 RPM $\approx$ 8.3ms per rotation. Avg delay $\approx$ 4.16ms.
3.  **Transfer Time ($T_{transfer}$):** Time to actually read/write the bits.
      * Function of bandwidth and data size.
      * $T_{transfer} = \frac{\text{Size of Transfer}}{\text{Transfer Rate}}$

### 1.3 The "Unwritten Contract"

Because seek and rotation are expensive mechanical operations:

  * **Sequential Access** $\gg$ **Random Access**.
  * Random I/O requires a seek/rotation for every request (throughput drops to $< 1$ MB/s).
  * Sequential I/O incurs seek/rotation once, then streams data (throughput $\approx$ 100+ MB/s).

### 1.4 Disk Scheduling Algorithms

The OS (or disk controller) reorders requests to minimize mechanical delays.

  * **FCFS (First-Come, First-Served):**
      * Fair but poor performance. Random requests lead to "head thrashing."
  * **SSTF (Shortest Seek Time First):**
      * Greedy strategy: Go to the nearest track.
      * *Pro:* Reduces total arm movement.
      * *Con:* **Starvation**. A stream of requests on inner tracks can prevent the head from ever servicing outer tracks.
  * **SCAN (Elevator Algorithm):**
      * Move arm in one direction (e.g., 0 to N), servicing requests. Reverse at the end.
      * *Pro:* No starvation.
      * *Con:* "Middle" tracks get serviced twice as often as edges.
  * **C-SCAN (Circular SCAN):**
      * Move 0 to N, then **reset immediately** to 0 without servicing on the return trip.
      * *Pro:* Uniform wait time for all tracks.
  * **SPTF (Shortest Positioning Time First):**
      * Considers **both** Seek and Rotation.
      * Ideally, the drive knows exactly where the sector is rotationally. If seeking further allows us to catch a sector *before* it spins away, SPTF takes that path.

-----

## Part 2: Concurrency & Code Patterns

*Focus: Exam-style coding problems, locks, and synchronization.*

### 2.1 Process vs. Thread State

When a program is multi-threaded, memory is divided into **Private** (per-thread) and **Shared** (process-wide).

| Memory Segment | Shared? | Why? |
| :--- | :--- | :--- |
| **Code / Text** | **Yes** | All threads execute the same program instructions. |
| **Global Variables** | **Yes** | Data accessible by all functions. |
| **Heap** | **Yes** | Dynamic memory (`malloc`) is shared. |
| **Open Files (FDs)** | **Yes** | If thread A opens a file, thread B can read it. |
| **Stack** | **NO** | Each thread needs its own function call history/local vars. |
| **Registers (PC, SP)** | **NO** | Each thread has its own execution context. |

### 2.2 The Bakery Algorithm (Software Mutual Exclusion)

*Context: Achieving mutual exclusion without hardware atomic instructions (like CAS).*

**Concept:**
Imagine a deli. You take a number (ticket). The person with the lowest number gets served next.

1.  **Choosing:** You signal you are taking a number.
2.  **Number Assignment:** You look at everyone else's number and pick `max(all_numbers) + 1`.
3.  **Wait:** You wait until everyone with a smaller number (or same number but smaller Thread ID) finishes.

**Key Code Logic (from Exam):**

```c
// acquire(me)
choosing[me] = TRUE;              // 1. Guard against race during number selection
number[me] = FindMax() + 1;       // 2. Pick ticket
choosing[me] = FALSE;             // 3. Finished selection

for (other = 0; other < N; other++) {
    while (choosing[other]);      // Wait if someone is currently picking a number
    // Wait if 'other' has a ticket AND ('other' has priority)
    while (number[other] != 0 &&
          (number[other] < number[me] ||
          (number[other] == number[me] && other < me)));
}
```

  * **Why `choosing` is critical:** Without it, two threads could read the same `max` value simultaneously, pick the same `number`, pass the check loop, and enter the Critical Section together (Violation of Mutual Exclusion).

**Simplification with Hardware:**
If you have `fetch_and_add` (atomic), you don't need the `choosing` array or the loop to check others. You simply atomically get a unique ticket number.

### 2.3 Barrier Synchronization

*Context: Coordinate N threads so they all arrive at a point before any proceed.*

**Implementation using Semaphores (2 Threads):**
Use two semaphores to create a "handshake."

```c
sema_t s[2]; // Init to 0

void barrier2(int me) {
    int other = 1 - me;
    sema_signal(&s[me]); // Tell the other guy "I arrived"
    sema_wait(&s[other]); // Wait for the other guy to signal
}
```

**Implementation using Condition Variables (N Threads):**
Standard pattern using **Mesa Semantics** (Always use `while`, not `if`).

```c
mutex_t m;
cond_t cv;
int count = 0;
int total_threads = N;

void barrier(int me) {
    mutex_lock(&m);
    count++;
    if (count == total_threads) {
        cond_broadcast(&cv); // Wake EVERYONE up
        // Reset count for next phase if needed (or do it in a separate phase)
    } else {
        while (count < total_threads) {
            cond_wait(&cv, &m); // Sleep (releases lock atomically)
        }
    }
    mutex_unlock(&m);
}
```

-----

## Part 3: File Systems

*Focus: Layout, directory logic, and indexing efficiency.*

### 3.1 On-Disk Layout

Typical simple file system (like FATty) layout:
`[ Boot ] [ Superblock ] [ Bitmaps/Log ] [ FAT/Inodes ] [ Data Region ]`

  * **FAT (File Allocation Table):** A linked-list map stored in a dedicated region. Entry `k` points to the next block of the file.
  * **Inode:** A data structure containing metadata (size, permissions, timestamps) and pointers to data blocks.

### 3.2 Directory lookups

Directories are just files containing list of pairs: `(Name, Inode_Number)`.

**Path Traversal Cost (`/usr/bin/ls`):**

1.  Read root inode `/` (usually fixed, e.g., Inode 0 or 2).
2.  Read data block of `/` to find entry `"usr"`. Get Inode(usr).
3.  Read Inode(usr). Read data block of `usr` to find `"bin"`. Get Inode(bin).
4.  Read Inode(bin). Read data block of `bin` to find `"ls"`. Get Inode(ls).
5.  Read Inode(ls).
    *Result:* Many reads (Linear cost relative to path depth).

### 3.3 Full Path Indexing (Optimization)

Instead of recursive traversal, maintain a global **Hash Map** or **B-Tree** where:

  * **Key:** Full path string (`"/usr/bin/ls"`)

  * **Value:** Inode Number.

  * **Pros:** O(1) or O(log N) lookup time. Very fast `open()`.

  * **Cons:**

      * **Space:** Storing full strings is redundant (high storage overhead).
      * **Rename:** Renaming a parent directory (`mv /usr /foo`) requires updating the keys for *every* child file (`/foo/bin/...`).
      * **Hard Links:** Hard links create multiple names for one inode; difficult to manage in a strict 1:1 map.

-----

## Part 4: Key Terminology Checklist (Exam Prep)

  * **Race Condition:** Output depends on the timing/ordering of thread execution.
  * **Spin Lock:** A lock that busy-waits (consumes CPU). Requires a **preemptive** scheduler to work on a single core (otherwise, the holder never gets CPU to release it).
  * **Write Disturbance:** In Flash SSDs, writing to one page may flip bits in neighbors.
  * **fsync():** System call that forces dirty (buffered) data to be flushed to physical disk.
  * **Track Buffer:** The small RAM cache inside the HDD.
  * **DMA (Direct Memory Access):** Hardware feature allowing disk controller to write to RAM without CPU intervention.
  * **Context Switch Costs:**
      * *Procedure Call:* Cheapest (save Return Address).
      * *User Thread Switch:* Medium (Save Registers, PC, SP).
      * *Kernel Thread Switch:* Expensive (Mode switch to Kernel mode, TLB flush potentially).

-----

### **Next Step for You:**

Would you like me to generate a **practice coding problem** specifically for the **Barrier implementation** using Semaphores or Condition Variables, similar to Q4 of the exam? This is a high-probability topic for tests.