# 6.5 The Riemann-Stieltjes Integral

## 1. Motivation & Intuition
The Riemann-Stieltjes integral unifies the concept of "summation" (discrete) and "integration" (continuous) into a single operator.

* **The Physical Analogy (Moment of Inertia):**
    * **Discrete System:** Masses $m_i$ at positions $r_i$. Moment $I = \sum r_i^2 m_i$.
    * **Continuous Wire:** Density $\rho(x)$. Moment $I = \int x^2 \rho(x) dx$.
    * **Unified View:** Let $m(x)$ be the cumulative mass distribution. We can write both as:
        $$I = \int r^2 dm(r)$$
    * Here, $dm$ represents the "weight" of the interval. If $m(x)$ jumps, we get a discrete mass; if $m(x)$ is smooth, we get density.

---

## 2. Definition of the Integral
Let $\alpha$ be a **monotonically increasing** function on $[a, b]$ (the "integrator" or weight function) and $f$ be a bounded function (the integrand).

### The Setup
1.  **Partition:** $\mathcal{P} = \{x_0, x_1, \dots, x_n\}$ dividing $[a, b]$.
2.  **The $\alpha$-Length:** Instead of $\Delta x_i$, we use the change in $\alpha$:
    $$\Delta \alpha_i = \alpha(x_i) - \alpha(x_{i-1}) \geq 0$$
3.  **Bounds:**
    $$M_i = \sup \{f(t) : t \in [x_{i-1}, x_i]\}$$
    $$m_i = \inf \{f(t) : t \in [x_{i-1}, x_i]\}$$

### Upper and Lower Sums
* **Upper Sum:** $\mathcal{U}(\mathcal{P}, f, \alpha) = \sum_{i=1}^n M_i \Delta \alpha_i$
* **Lower Sum:** $\mathcal{L}(\mathcal{P}, f, \alpha) = \sum_{i=1}^n m_i \Delta \alpha_i$

### Definition of Integrability
$f$ is Riemann-Stieltjes integrable with respect to $\alpha$ ($f \in \mathcal{R}(\alpha)$) if the infimum of upper sums equals the supremum of lower sums:
$$\underline{\int_a^b} f d\alpha = \sup_{\mathcal{P}} \mathcal{L}(\mathcal{P}, f, \alpha) = \inf_{\mathcal{P}} \mathcal{U}(\mathcal{P}, f, \alpha) = \overline{\int_a^b} f d\alpha$$
The common value is denoted $\int_a^b f d\alpha$.

---

## 3. Existence & Criteria for Integrability

### Theorem 6.5.5: Cauchy Criterion
$f \in \mathcal{R}(\alpha)$ if and only if for every $\epsilon > 0$, there exists a partition $\mathcal{P}$ such that:
$$\mathcal{U}(\mathcal{P}, f, \alpha) - \mathcal{L}(\mathcal{P}, f, \alpha) < \epsilon$$
* **Proof Intuition:** This mirrors the standard Riemann integral. If the difference between the "over-estimate" and "under-estimate" can be made arbitrarily small, they must converge to a single number.

### Theorem 6.5.6: Sufficient Conditions
This is a critical theorem establishing *when* we can calculate this integral.

#### Case A: $f$ is Continuous
**Theorem:** If $f$ is continuous on $[a, b]$, then $f \in \mathcal{R}(\alpha)$.
* **Proof Strategy (Uniform Continuity):**
    1.  Since $f$ is continuous on a compact set $[a, b]$, it is **uniformly continuous**.
    2.  Given $\epsilon$, choose $\eta$ such that $|x-y|<\eta \implies |f(x)-f(y)| < \frac{\epsilon}{\alpha(b)-\alpha(a)}$.
    3.  Choose a partition $\mathcal{P}$ with mesh size $< \eta$.
    4.  Then $M_i - m_i < \frac{\epsilon}{\alpha(b)-\alpha(a)}$ for all $i$.
    5.  Compute difference:
        $$\mathcal{U} - \mathcal{L} = \sum (M_i - m_i)\Delta \alpha_i < \frac{\epsilon}{\alpha(b)-\alpha(a)} \sum \Delta \alpha_i = \epsilon$$

#### Case B: $f$ is Monotone, $\alpha$ is Continuous
**Theorem:** If $f$ is monotone and $\alpha$ is continuous, then $f \in \mathcal{R}(\alpha)$.
* **Proof Strategy (Uniform $\alpha$-grid):**
    1.  We cannot rely on $f$'s continuity here. Instead, we use the continuity of $\alpha$.
    2.  By Intermediate Value Theorem on $\alpha$, we can choose a partition such that all $\Delta \alpha_i$ are equal:
        $$\Delta \alpha_i = \frac{\alpha(b) - \alpha(a)}{n}$$
    3.  Assume $f$ is increasing. Then $M_i = f(x_i)$ and $m_i = f(x_{i-1})$.
    4.  The sum telescopes:
        $$\mathcal{U} - \mathcal{L} = \sum (f(x_i) - f(x_{i-1})) \frac{\alpha(b)-\alpha(a)}{n} = \frac{\alpha(b)-\alpha(a)}{n} (f(b) - f(a))$$
    5.  As $n \to \infty$, this difference goes to 0.

---

## 4. Properties and Calculus Rules

### Theorem 6.5.8: Algebraic Properties
1.  **Linearity:** $\int (f+g)d\alpha = \int f d\alpha + \int g d\alpha$ and $\int c f d\alpha = c \int f d\alpha$.
2.  **Additivity in $\alpha$:** $\int f d(\alpha_1 + \alpha_2) = \int f d\alpha_1 + \int f d\alpha_2$.
3.  **Domain Splitting:** $\int_a^b = \int_a^c + \int_c^b$.
4.  **Boundedness:** If $|f(x)| \le M$, then $|\int_a^b f d\alpha| \le M(\alpha(b)-\alpha(a))$.

### Theorem 6.5.9: Mean Value Theorem
If $f$ is continuous and $\alpha$ is monotone increasing:
$$\exists c \in [a, b] \text{ such that } \int_a^b f d\alpha = f(c)[\alpha(b) - \alpha(a)]$$
* **Proof:** Let $m = \inf f, M = \sup f$. By monotonicity of integral:
    $$m[\alpha(b)-\alpha(a)] \le \int f d\alpha \le M[\alpha(b)-\alpha(a)]$$
    By the Intermediate Value Theorem, $f$ must attain the value $\frac{\int f d\alpha}{\alpha(b)-\alpha(a)}$ at some point $c$.

### Theorem 6.5.10: Integration by Parts
If $\alpha$ and $\beta$ are monotone increasing, then $\alpha \in \mathcal{R}(\beta) \iff \beta \in \mathcal{R}(\alpha)$.
$$\int_a^b \alpha d\beta + \int_a^b \beta d\alpha = \alpha(b)\beta(b) - \alpha(a)\beta(a)$$
* **Proof Insight (Abel's Summation):**
    Consider the sum for $\int \alpha d\beta$. We can manipulate the partition sums algebraically:
    $$\sum \alpha(t_i)[\beta(x_i) - \beta(x_{i-1})] \approx [\alpha \beta]_a^b - \sum \beta(t_i)[\alpha(x_i) - \alpha(x_{i-1})]$$
    This is the discrete analogue of the product rule $(fg)' = f'g + fg'$.

---

## 5. Computing the Integral (The Two Extremes)

This is the practical side: how do we actually evaluate these integrals?

### A. The Discrete Case (Step Functions)
Let $I_c(x)$ be the unit jump function (0 if $x < c$, 1 if $x \ge c$).
If $\alpha(x) = \sum_{n=1}^N c_n I(x - s_n)$ (a staircase function with jumps at $s_n$), then:
$$\int_a^b f d\alpha = \sum_{n=1}^N c_n f(s_n)$$
* **Condition:** $f$ must be continuous at the jump points $s_n$.
* **Proof Logic:** Around a jump $s_n$, the $\Delta \alpha$ is non-zero (it's $c_n$). The interval width $\Delta x$ shrinks to 0. Since $f$ is continuous, $f(x)$ on that tiny interval is squeezed to $f(s_n)$. The integral effectively "samples" $f$ at the jump points.

### B. The Smooth Case (Reduction to Riemann)
**Theorem 6.5.12:** If $\alpha$ is differentiable and $\alpha'$ is Riemann integrable, then:
$$\int_a^b f(x) d\alpha(x) = \int_a^b f(x) \alpha'(x) dx$$
* **Proof Logic (Mean Value Theorem):**
    1.  In the sum $\sum f(t_i) \Delta \alpha_i$, apply MVT to $\alpha$:
        $$\Delta \alpha_i = \alpha(x_i) - \alpha(x_{i-1}) = \alpha'(c_i) \Delta x_i$$
        where $c_i \in (x_{i-1}, x_i)$.
    2.  The sum becomes $\sum f(t_i) \alpha'(c_i) \Delta x_i$.
    3.  This looks like a Riemann sum for the product function $f(x)\alpha'(x)$.
    4.  Technicality: $t_i$ (from $f$) and $c_i$ (from MVT) might differ, but uniform continuity arguments allow us to replace them and show convergence.

---

## 6. Riemann-Stieltjes Sums (A Warning)

A Riemann-Stieltjes Sum is defined as $\mathcal{S}(\mathcal{P}, f, \alpha) = \sum_{i=1}^n f(t_i) \Delta \alpha_i$ where $t_i$ is an arbitrary tag in $[x_{i-1}, x_i]$.

### The Convergence Trap (Example 6.5.15)
In standard calculus, $\lim_{|\mathcal{P}|\to 0} S = I$ is equivalent to integrability. **This is not always true for Stieltjes.**

* **Scenario:**
    * $f(x)$: Step function jumping from 0 to 1 at $x=1$ (Left continuous).
    * $\alpha(x)$: Step function jumping from 0 to 1 at $x=1$ (Left continuous).
* **Result:**
    * The integral $\int f d\alpha$ is defined and equals 0 (using upper/lower integrals).
    * **However**, the limit of sums $\lim \mathcal{S}(\mathcal{P}, f, \alpha)$ **does not exist**.
* **Why?** If the partition point falls exactly on the jump $x=1$, choosing the tag $t_i = 1$ gives $f(1)=0$ (sum=0), but choosing $t_i > 1$ gives $f(t_i)=1$ (sum=1).
* **Takeaway:** If $f$ and $\alpha$ share a discontinuity, the limit of sums may fail even if the integral (defined via sup/inf) exists. If $f$ is continuous, the limit holds.